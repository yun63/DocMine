## 海量数据处理问题总结

### 1 TOP K问题

#### 1.1 如何在海量数据中找出重复最多的1个

* 通过hash映射成小文件
* 通过map统计各个小文件重复最多的并记录次数
* 对每个小文件重复最多的数据建立大顶堆

#### 1.2 上亿有重数据，统计最多前N个

1. 内存存得下
   * 直接map统计并建立大顶堆
   * 重复N次取走堆顶并重建堆操作
2. 内存放不下
   * 通过hash映射成小文件
   * 通过map统计各个小文件中重复次数最多的前K个记录并记录次数
   * 对所有的小文件重复次数最多的前K个记录建立大顶堆，并重复K次取走堆顶元素，再重建堆

#### 1.3 海量日志数据，提取出某日访问百度次数最多的那个IP

1. 将IP%1000映射到1000个小文件中
   * 相同IP会被映射到同一个文件中
   * 不会出现累加和更大情况
2. 分1000次在内存中处理小文件，得到频率最大的IP（使用map统计）
3. 对这1000个IP建立大顶堆

#### 1.4 1000w查询字符串统计最热门的10个（同1.2）

#### 1.5 1G的文件，里面1行1个不超过16字节的单词。内存限制1M，返回词频最高的前100个

* 将单词 % 5000存入5000个小文件中
  * 平均每个小文件200k
  * 对超过1M的文件继续分割直到小于200k
* 使用map统计各个单词出现的频次
* 对5000个次使用堆排序或归并排序

---

### 2 分布式TOP N问题

#### 2.1 分布在100台电脑的海量数据，统计前10

* 每个数据只出现在一台机器中
  * 先在独立机器得到top10
  * 再将100台机器的top10组合起来堆排序
* 每个数据可同时出现在不同机器中
  * 遍历所有数据，重新hash取模，使得同一个数据只出现在单独的一台机器上，然后利用上面的方法，在每台机器上统计top10，最后汇总起来

### 3 外排序问题

#### 3.1 有10个1G文件，每行都是一个可重复用户的query， 按query频度排序

* 依次读取10个文件，对每个query进行hash，输出到10个文件中去
* 通过map统计每个query出现的次数，至少2G内存，按照次数进行排序，重新输出到新文件中，得到已排序文件
* 对10个已排好序的文件进行归并排序（外排序）

#### 3.2 现有A，B两个文件各存放50亿条URL，每个URL占64字节，找出公共的URL，限制内存4GB

* 依次对A和B文件中的每条URL，通过URL%1000将URL数据映射到1000个文件中，得到A1，A2，...，A1000，B1，B2，...，B1000

* 依次遍历Ai文件，将Ai文件中的URL存放到set中，再遍历对应的Bi文件，监测Ai中的URL是否再Bi中出现即可

  