[缓存更新的套路](https://coolshell.cn/articles/17416.html)

=============

### 1 错误策略：

删除缓存 -> 更新数据库 -> 读数据再装载到缓存

> 试想，两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。



### 2 更新缓存4中设计模式

1. Cache aside

   * 不命中：应用程序先从cache中取数据，取不到，则从数据库中取数据，成功后，放到缓存中

   * 命中：应用程序从cache中取数据，命中后直接返回
   * 更新：先把数据存到数据库中，成功后，再让缓存失效

   > 一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。

   这是标准的设计，那么是不是Cache aside就不会有并发问题了呢？不是的，比如：

   > 一个是读操作，但没有命中缓存，然后到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。
   >
   > 但是，这个case理论上会出现，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且需要锁表，而读操作必须在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率极小。

   **为缓存设置上过期时间**

   **Read/Write Through 模式**

   > 在上面的Cache aside模式中，应用程序代码需要为患两个数据存储：缓存cache和数据库db，所以，应用程序代码比较啰嗦。而Read/Write through是把更新数据库的操作由缓存自己代理了。所以，对应用程序来说，就简单多了。
   >
   > **可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的cache。**

2. Read Through

   Read Through套路就是在查询操作中更新缓存，也就是说，当缓存试下的时候，Cache

    Aside是由调用方把数据加载到缓存，而Read Through则用缓存服务自己来加载，从而对应用程序是透明的

3. Write Through

   Write Through套路和Read Through相仿，不过是在更新数据时发生。

   当有数据更新的时候，如果没有命中缓存，直接更新数据库并返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（同步操作）

4. Write behind caching

   Write Behind又叫Write Back，就是Linux文件系统的Page Cache算法。

   Write Back套路，一句话就是，在更新数据的时候，这更新缓存，不在更新数据库，而我们的缓存会异步地批量更新数据库，这个设计的好处就是数据的I/O操作飞快无比（因为直接操作内存），因为异步，Write Back还可以合并对一个数据的多次操作，所以性能的提高是相当可观的。

   但是，带来的问题就是，数据不是强一致性的，而且可能会丢失（Linux系统非正常关机会导致数据丢失，就是因为这个事）

   **在软件设计上，我们基本上不可能设计出一个没有缺陷的设计，就像算法设计中时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性能是有冲突的，软件设计从来都是取舍**